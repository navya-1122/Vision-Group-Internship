{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOBiWdWLlmUTSHJLXT+Hh2z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navya-1122/Vision-Group-Internship/blob/main/Tensorflow-Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nRYUS9y0PID"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Display the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# other imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "# Distribute it to train and test set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "qeMzca3I0d4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# flatten the label values\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()"
      ],
      "metadata": {
        "id": "CKSKQ4Uo0j75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize data by plotting images\n",
        "fig, ax = plt.subplots(5, 5)\n",
        "k = 0\n",
        "\n",
        "for i in range(5):\n",
        "    for j in range(5):\n",
        "        ax[i][j].imshow(x_train[k], aspect='auto')\n",
        "        k += 1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WIQHBwml0owy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of classes\n",
        "K = len(set(y_train))\n",
        "\n",
        "# calculate total number of classes\n",
        "# for output layer\n",
        "print(\"number of classes:\", K)\n",
        "\n",
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=x_train[0].shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-DFFC5ob0sSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-Q30i0Dc0uhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit\n",
        "r = model.fit(\n",
        "  x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
      ],
      "metadata": {
        "id": "NKFbKhj90v_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit with data augmentation\n",
        "# Note: if you run this AFTER calling\n",
        "# the previous model.fit()\n",
        "# it will CONTINUE training where it left off\n",
        "batch_size = 32\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "  width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "train_generator = data_generator.flow(x_train, y_train, batch_size)\n",
        "steps_per_epoch = x_train.shape[0] // batch_size\n",
        "\n",
        "r = model.fit(train_generator, validation_data=(x_test, y_test),\n",
        "              steps_per_epoch=steps_per_epoch, epochs=50)"
      ],
      "metadata": {
        "id": "YoXL4EtL0xqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy per iteration\n",
        "plt.plot(r.history['accuracy'], label='acc', color='red')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc', color='green')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "7EOtwwWn0zCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label mapping\n",
        "\n",
        "labels = '''airplane automobile bird cat deerdog frog horseship truck'''.split()\n",
        "\n",
        "# select the image from our test dataset\n",
        "image_number = 0\n",
        "\n",
        "# display the image\n",
        "plt.imshow(x_test[image_number])\n",
        "\n",
        "# load the image in an array\n",
        "n = np.array(x_test[image_number])\n",
        "\n",
        "# reshape it\n",
        "p = n.reshape(1, 32, 32, 3)\n",
        "\n",
        "# pass in the network for prediction and\n",
        "# save the predicted label\n",
        "predicted_label = labels[model.predict(p).argmax()]\n",
        "\n",
        "# load the original label\n",
        "original_label = labels[y_test[image_number]]\n",
        "\n",
        "# display the result\n",
        "print(\"Original label is {} and predicted label is {}\".format(\n",
        "    original_label, predicted_label))"
      ],
      "metadata": {
        "id": "spyD0GQN0082"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model.save('123.h5')"
      ],
      "metadata": {
        "id": "7uoGCOhH03It"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}